# -*- coding: utf-8 -*-
"""Youtube_Veri_Analiz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C-0gcZoN2P_PGjnjStA2D3-S13bJQRuI

# Veri Okuma ve Temizleme İşlemleri
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.ticker as mtick

data_set = pd.read_csv('noluyo_ya_youtube_videos_data.csv')
data_set.info()
data_set.isnull().sum() # Hangi alanda eksik değer var ve sayısı
data_set = data_set.dropna() # null değerlerin temizlenmesi
data_set.head(10) # 10 row gösterir. İlk index 0 oluyor.

"""# Analizler"""

# En Çok İzlenen Video
en_cok_izlenen = data_set.loc[data_set['view_count'].idxmax()] # maksimum değere sahip satırı verir
print("En Çok İzlenen Video:")
print(f"Video Başlığı: {en_cok_izlenen['title']}")
print(f"İzlenme Sayısı: {en_cok_izlenen['view_count']}")
print(f"Video ID: {en_cok_izlenen['video_id']}")
print("—" * 80)

# En Çok Yorum Alan Video
en_cok_yorum = data_set.loc[data_set['comment_count'].idxmax()]
print("En Çok Yorum Alan Video:")
print(f"Video Başlığı: {en_cok_yorum['title']}")
print(f"Yorum Sayısı: {en_cok_yorum['comment_count']}")
print(f"Video ID: {en_cok_yorum['video_id']}")
print("—" * 80)

# En Çok Beğeni Alan Video
en_cok_begeni = data_set.loc[data_set['like_count'].idxmax()]
print("En Çok Beğeni Alan Video:")
print(f"Video Başlığı: {en_cok_begeni['title']}")
print(f"Beğeni Sayısı: {en_cok_begeni['like_count']}")
print(f"Video ID: {en_cok_begeni['video_id']}")
print("—" * 80)

# En Az İzlenen Video
en_az_izlenen = data_set.loc[data_set['view_count'].idxmin()] # minumum değere sahip satırı verir
print("En Az İzlenen Video:")
print(f"Video Başlığı: {en_az_izlenen['title']}")
print(f"İzlenme Sayısı: {en_az_izlenen['view_count']}")
print(f"Video ID: {en_az_izlenen['video_id']}")
print("—" * 80)

# En Az Yorum Alan Video
en_az_yorum = data_set.loc[data_set['comment_count'].idxmin()]
print("En Az Yorum Alan Video:")
print(f"Video Başlığı: {en_az_yorum['title']}")
print(f"Yorum Sayısı: {en_az_yorum['comment_count']}")
print(f"Video ID: {en_az_yorum['video_id']}")
print("—" * 80)

# En Az Beğeni Alan Video
en_az_begeni = data_set.loc[data_set['like_count'].idxmin()]
print("En Az Beğeni Alan Video:")
print(f"Video Başlığı: {en_az_begeni['title']}")
print(f"Beğeni Sayısı: {en_az_begeni['like_count']}")
print(f"Video ID: {en_az_begeni['video_id']}")
print("—" * 80)

"""# Görselleştirme"""

# İzlenme sayılarına göre
df_sorted = data_set.sort_values(by='view_count', ascending=False)

plt.figure(figsize=(10, 6))
bars = plt.barh(df_sorted['title'][:10], df_sorted['view_count'][:10], color='skyblue')
plt.xlabel('İzlenme Sayısı')
plt.title('En Çok İzlenen 10 Video')
plt.gca().invert_yaxis()

for bar, view_count in zip(bars, df_sorted['view_count'][:10]):
    plt.text(view_count, bar.get_y() + bar.get_height() / 2, f'{view_count:,}', va='center', ha='left', fontsize=9, color='black')

plt.show()

# Beğeni sayılarına göre sıralama
df_sorted = data_set.sort_values(by='like_count', ascending=False)

# Grafik oluşturma
plt.figure(figsize=(10, 6))
bars = plt.barh(df_sorted['title'][:10], df_sorted['like_count'][:10], color='lightgreen')
plt.xlabel('Beğeni Sayısı')
plt.title('En Çok Beğenilen 10 Video')
plt.gca().invert_yaxis()

for bar, like_count in zip(bars, df_sorted['like_count'][:10]):
    plt.text(like_count, bar.get_y() + bar.get_height() / 2, f'{like_count:,}', va='center', ha='left', fontsize=9, color='black')

plt.show()



plt.figure(figsize=(12, 8))

# Görüntülenme Sayısı Dağılımı
plt.subplot(2, 2, 1)
sns.histplot(data_set['view_count'], kde=True)
plt.title('Görüntülenme Sayısı Dağılımı')
plt.xlabel('Görüntülenme Sayısı (M)')
plt.ylabel('Video Sayısı')

# X eksenini 4M aralıklarla ayarla
max_views = data_set['view_count'].max()
plt.xticks(np.arange(0, max_views + 4_000_000, 4_000_000))

# X ekseni formatını milyonlar (M) şeklinde göster
plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f'{int(x / 1_000_000)}M'))

plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 8))

# Beğeni dağılımı
plt.subplot(2, 2, 1)
sns.histplot(data_set['like_count'], kde=True)
plt.title('Beğeni Sayısı Dağılımı')
plt.xlabel('Beğeni Sayısı')

# X eksenini 100K aralıklarla ayarla
max_likes = data_set['like_count'].max()
plt.xticks(np.arange(0, max_likes + 100_000, 100_000))

# X ekseni formatını "100K", "200K" şeklinde göster
plt.gca().xaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f'{int(x/1000)}K'))

plt.tight_layout()
plt.show()

numeric_features = ['view_count', 'like_count', 'comment_count', 'duration']
df_numeric = data_set[numeric_features].copy()

# Korelasyon Matrisi
plt.subplot(2, 2, 3)
correlation_matrix = df_numeric.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Korelasyon Matrisi')

# Görüntülenme ve beğeni sayısı arasındaki ilişki
plt.figure(figsize=(8, 5))

# Görüntülenme ve Beğeni İlişkisi (Regresyon Çizgili)
sns.scatterplot(x='view_count', y='like_count', data=data_set, label="Veri Noktaları")
sns.regplot(x='view_count', y='like_count', data=data_set, scatter=False, color='red', label="Regresyon Çizgisi")

plt.title('Görüntülenme ve Beğeni İlişkisi')
plt.xlabel('Görüntülenme Sayısı')
plt.ylabel('Beğeni Sayısı')
plt.legend()
plt.tight_layout()
plt.show()

# Beğeni/görüntülenme oranı oluşturma (engagement rate)
data_set['engagement_rate'] = (data_set['like_count'] / data_set['view_count']) * 100


print("\nEtkileşim Oranı İstatistikleri:")
print(data_set['engagement_rate'].describe())


# Yorum/görüntülenme oranı oluşturma
data_set['comment_rate'] = (data_set['comment_count'] / data_set['view_count']) * 100
print("\nYorum Oranı İstatistikleri:")
print(data_set['comment_rate'].describe())

data_set.head(10)

"""# Kümeleme Analizi"""

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

#Kümeleme için kullanılacak özellikler (view_count, like_count, comment_count, duration) bir liste (cluster_features) olarak tanımlanır.
#Bu özellikler, veri setinden (data_set) seçilerek yeni bir veri çerçevesi (df_cluster) oluşturulur.

cluster_features = ['view_count', 'like_count', 'comment_count', 'duration']
df_cluster = data_set[cluster_features].copy()

#Farklı ölçeklerdeki özellikleri (örneğin, görüntülenme sayısı binlerle, süre saniyelerle ölçülür) karşılaştırılabilir hale getirmek için z-skoru standardizasyonu uygulanır.
#StandardScaler sınıfı kullanılarak, her bir özelliğin ortalaması 0 ve standart sapması 1 olacak şekilde dönüştürülür:
#fit_transform: Veriyi önce öğrenir (fit) ve ardından dönüştürür (transform).
df_cluster_scaled = StandardScaler().fit_transform(df_cluster)
#print(df_cluster_scaled)

#K-Means algoritması için en uygun küme sayısı (k), Elbow Metodu kullanılarak belirlenir.
#Bu yöntem, farklı k değerleri için kümeleme yapıldıktan sonra inertia (kümeler içindeki kareler toplamı) değerlerini analiz eder.
#Eğilim, kümeler içindeki noktaların merkezlere olan uzaklıklarının karelerinin toplamıdır ve daha fazla küme eklendikçe azalır.
#Ancak, belirli bir noktadan sonra eklenen kümeler anlamlı bir iyileşme sağlamaz; bu nokta "dirsek" (elbow) olarak adlandırılır.

inertia = []
k_range = range(1, min(11, len(df_cluster)))

#KMeans Parametreleri:
#n_clusters=k: Denenecek küme sayısı.
#random_state=1: Tekrarlanabilirlik için rastgelelik kontrolü.
#n_init=10: Algoritmanın farklı başlangıç merkezleriyle 10 kez çalıştırılıp en iyi sonucun seçilmesi.

#k_range: 1’den veri setindeki satır sayısına veya 10’a kadar (hangisi küçükse) denenir.
for k in k_range:
    try:
        kmeans = KMeans(n_clusters=k, random_state=1, n_init=10)
        kmeans.fit(df_cluster_scaled)
        inertia.append(kmeans.inertia_)
    except:
        # Yetersiz veri durumunda hata oluşabilir
        break

cluster_mapping = {
    0: 'Düşük Etkileşimli Videolar',
    1: 'Orta Popüler Videolar',
    2: 'Yüksek Popüler Videolar',
    3: 'Özel/Niş Videolar'
}

custom_palette = {
    'Düşük Etkileşimli Videolar': '#FF9999',  # Kırmızı tonları
    'Orta Popüler Videolar': '#66B2FF',      # Mavi tonları
    'Yüksek Popüler Videolar': '#99FF99',    # Yeşil tonları
    'Özel/Niş Videolar': '#FFD700'           # Altın sarısı
}

# Görselleştirme - Elbow metodu
if len(inertia) > 1:
    plt.figure(figsize=(10, 6))
    plt.plot(k_range[:len(inertia)], inertia, 'bo-')
    plt.xlabel('Küme Sayısı')
    plt.ylabel('Eğilim')
    plt.title('Elbow Metodu')


    # Optimal küme sayısını belirleyip K-means uygulama
    # Optimal küme sayısı (optimal_k) manuel olarak 4 olarak belirlenmiştir (ancak bu değer, Elbow grafiğine göre değiştirilebilir). K-Means algoritması, standartlaştırılmış veri üzerinde çalıştırılır
    optimal_k = 4  # Bu değeri elbow grafiğine göre değiştirebiliz
    kmeans = KMeans(n_clusters=optimal_k, random_state=1, n_init=10)
    data_set['cluster'] = kmeans.fit_predict(df_cluster_scaled)
    data_set['cluster_text'] = data_set['cluster'].map(cluster_mapping)

    # Kümelerin analizi
    # Kümelerin özelliklerini anlamak için, veri seti küme etiketlerine göre gruplandırılır ve her küme için aşağıdaki özelliklerin ortalamaları hesaplanır:
    cluster_analysis = data_set.groupby('cluster_text').agg({
        'view_count': 'mean',
        'like_count': 'mean',
        'comment_count': 'mean',
        'duration': 'mean',
        'engagement_rate': 'mean',
        'comment_rate': 'mean',
        'video_id': 'count'
    }).reset_index()

    print("\nKüme Analizi Sonuçları:")
    print(cluster_analysis)


    # Kümelere göre dağılımın görselleştirilmesi
    plt.figure(figsize=(12, 8))

    sns.scatterplot(
    x='view_count',
    y='like_count',
    hue='cluster_text',
    data=data_set,
    palette=custom_palette,
    s=100,  # Nokta büyüklüğü
    alpha=0.7,  # Şeffaflık
    edgecolor='w'  # Beyaz kenarlık
)

    #sns.scatterplot(x='view_count', y='like_count', hue='cluster_text', data=data_set, palette='viridis')
    plt.title('Video Kümeleri: Görüntülenme vs Beğeni')
    plt.xlabel('Görüntülenme Sayısı')
    plt.ylabel('Yorum Sayısı')


        # Kümelere göre dağılımın görselleştirilmesi
    plt.figure(figsize=(12, 8))
    sns.scatterplot(
    x='view_count',
    y='comment_count',
    hue='cluster_text',
    data=data_set,
    palette=custom_palette,
    s=100,  # Nokta büyüklüğü
    alpha=0.7,  # Şeffaflık
    edgecolor='w'  # Beyaz kenarlık
)

    #sns.scatterplot(x='view_count', y='like_count', hue='cluster_text', data=data_set, palette='viridis')
    plt.title('Video Kümeleri: Görüntülenme vs Yorum')
    plt.xlabel('Görüntülenme Sayısı')
    plt.ylabel('Beğeni Sayısı')
#data_set.head(10)



